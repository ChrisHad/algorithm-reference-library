{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation of compression for LOW data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline dependent averaging is a form of data compression. In this script, we create a critically sampled snapshot of a LOW data set, and then compress and decompress it to see what errors result. We look at the time required for all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from time import clock\n",
    "\n",
    "sys.path.append(os.path.join('..', '..'))\n",
    "\n",
    "from matplotlib import pylab\n",
    "\n",
    "pylab.rcParams['agg.path.chunksize'] = 10000\n",
    "pylab.rcParams['figure.figsize'] = (12.0, 12.0)\n",
    "pylab.rcParams['image.cmap'] = 'rainbow'\n",
    "\n",
    "import numpy\n",
    "\n",
    "from astropy.convolution import Gaussian2DKernel, convolve\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import cm \n",
    "\n",
    "from arl.visibility.operations import create_visibility, vis_summary\n",
    "from arl.skymodel.operations import create_skycomponent, insert_skycomponent\n",
    "from arl.image.operations import show_image, export_image_to_fits, import_image_from_fits, qa_image, \\\n",
    "    create_image_from_array, reproject_image, copy_image\n",
    "from arl.fourier_transforms.fft_support import extract_mid\n",
    "from arl.visibility.compress import compress_visibility, decompress_visibility\n",
    "from arl.image.iterators import raster_iter\n",
    "from arl.visibility.iterators import vis_timeslice_iter\n",
    "from arl.util.testing_support import create_named_configuration, create_low_test_image, create_low_test_beam\n",
    "from arl.fourier_transforms.ftprocessor import *\n",
    "\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.DEBUG)\n",
    "log.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the configuration and fill in the appropriate sampling values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = 'core'\n",
    "if config == 'full':\n",
    "    low = create_named_configuration('LOWBD2')\n",
    "    b = 8e4\n",
    "    cellsize = 0.000015\n",
    "    npixel=2048\n",
    "    nsnapshots = 30\n",
    "\n",
    "else:\n",
    "    low = create_named_configuration('LOWBD2-CORE')\n",
    "    b = 4e3\n",
    "    cellsize = 0.0015\n",
    "    npixel=256\n",
    "    nsnapshots = 1000\n",
    "\n",
    "    \n",
    "oversampling = 32\n",
    "\n",
    "sampling_time = 35.0 / (oversampling * b)\n",
    "log.info(\"Critical sampling time = %.5f (radians) %.2f (seconds)\" % \n",
    "         (sampling_time, sampling_time * 43200.0 / numpy.pi))\n",
    "sampling_frequency = 1e8 * 35.0 / (oversampling * b) \n",
    "log.info(\"Critical sampling frequency = %.5f (Hz) \" % (sampling_frequency))\n",
    "times = numpy.arange(0.0, + nsnapshots * sampling_time, sampling_time)\n",
    "frequency = numpy.linspace(1e8 - sampling_frequency, 1e8 + sampling_frequency, 3)\n",
    "frequency = numpy.array([1e8])\n",
    "\n",
    "log.info(\"Observing frequencies %s Hz\" % (frequency))\n",
    "\n",
    "log.info(\"Cellsize = %.6f radians\" % (cellsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the visibility holding the vis, uvw, time, antenna1, antenna2, weight columns in a table. The actual visibility values are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phasecentre = SkyCoord(ra=+0.0 * u.deg, dec=-26.7 * u.deg, frame='icrs', equinox=2000.0)\n",
    "vt = create_visibility(low, times, frequency, weight=1.0, phasecentre=phasecentre, npol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the standard LOW test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = create_low_test_image(npixel=npixel, cellsize=cellsize, phasecentre=phasecentre, frequency=frequency[0])\n",
    "model.data[model.data>10]=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the low beam and apply it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "beam=create_low_test_beam(model)\n",
    "model.data*=beam.data\n",
    "show_image(beam)\n",
    "mask = copy_image(beam)\n",
    "mask.data[beam.data>0.1]=1.0\n",
    "mask.data[beam.data<=0.1]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmodel = create_image_from_array(convolve(model.data[0,0,:,:], Gaussian2DKernel(1.0), normalize_kernel=True), \n",
    "                                 model.wcs)\n",
    "norm = numpy.max(model.data)/numpy.max(model.data)\n",
    "cmodel.data *= norm\n",
    "show_image(cmodel)\n",
    "plt.title(\"Smoothed model image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in with the visibility of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vt.data['vis'] *= 0.0\n",
    "vt.data['uvw'][:,2] = 0\n",
    "\n",
    "\n",
    "vt = predict_2d(vt, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress and plot the uv coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compression_factor=1.0\n",
    "\n",
    "cvt, cindex = compress_visibility(vt, compression='tb', compression_factor=compression_factor, max_compression=10)\n",
    "plt.clf()\n",
    "for chan in range(len(cvt.frequency)):\n",
    "    plt.plot(+cvt.uvw_lambda(chan)[:,0],+cvt.uvw_lambda(chan)[:,1], '.', color='b')\n",
    "    plt.plot(-cvt.uvw_lambda(chan)[:,0],-cvt.uvw_lambda(chan)[:,1], '.', color='b')\n",
    "plt.title('Compressed uv coverage')\n",
    "plt.xlabel('U (lambda)')\n",
    "plt.ylabel('V (lambda)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the dirty images from original and compressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirtyimage, sumwt = invert_2d(vt, model)\n",
    "dirtyimage=normalize_sumwt(dirtyimage, sumwt)\n",
    "show_image(dirtyimage)\n",
    "plt.title('Original data image')\n",
    "plt.show()\n",
    "\n",
    "cdirtyimage, csumwt=invert_2d(cvt, model)\n",
    "cdirtyimage=normalize_sumwt(cdirtyimage, csumwt)\n",
    "show_image(cdirtyimage)\n",
    "plt.title('Compressed data image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress and make the dirty image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dcvt = decompress_visibility(cvt, vt, cindex=cindex, compression='tb')\n",
    "\n",
    "dcdirtyimage, dcsumwt=invert_2d(dcvt, model)\n",
    "dcdirtyimage=normalize_sumwt(dcdirtyimage, dcsumwt)\n",
    "show_image(dcdirtyimage)\n",
    "plt.title('Decompressed data image')\n",
    "plt.show()\n",
    "\n",
    "dcdirtyimage.data -= dirtyimage.data\n",
    "show_image(dcdirtyimage)\n",
    "plt.title('Recovery error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signal=numpy.std(numpy.abs(vt.vis[:,0,0]))\n",
    "error=numpy.std(numpy.abs(vt.vis[:,0,0]-dcvt.vis[:,0,0]))\n",
    "uvdist=numpy.sqrt(vt.u**2+vt.v**2)\n",
    "plt.clf()\n",
    "plt.plot(vt.vis.real[:,0,0], vt.vis.imag[:,0,0], '.', color='b', label='Original')\n",
    "plt.plot(dcvt.vis.real[:,0,0]-vt.vis.real[:,0,0], dcvt.vis.imag[:,0,0]-vt.vis.imag[:,0,0],\n",
    "         '.', color='r', label='error')\n",
    "plt.xlabel('Real')\n",
    "plt.ylabel('Imaginary')\n",
    "plt.legend()\n",
    "plt.title(\"Compression = %.3f, rms signal = %.3f, rms error = %.3f\" %(compression_factor, signal, error))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do a range of compression factors to see how the recovery error varies. We compress and decompress and difference the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts = clock()\n",
    "dirtyimage, sumwt = invert_2d(vt, model)\n",
    "dirtyimage=normalize_sumwt(dirtyimage, sumwt)\n",
    "t_full = clock() - ts\n",
    "show_image(dirtyimage)\n",
    "plt.show()\n",
    "\n",
    "qa = qa_image(dirtyimage, mask=mask)\n",
    "print(\"Original image\", qa)\n",
    "\n",
    "template_vis = copy.deepcopy(vt)\n",
    "\n",
    "signal = []\n",
    "error_peak = []\n",
    "error_medianabs = []\n",
    "t_invert = []\n",
    "t_compresses = []\n",
    "t_decompresses = []\n",
    "\n",
    "compression_factors = [4.0, 2.0, 1.0, 0.5, 0.25, 0.0]\n",
    "\n",
    "for compression_factor in compression_factors:\n",
    "    ts = clock()\n",
    "    cvt, cindex = compress_visibility(vt, compression='tb', compression_factor=compression_factor, max_compression=100)\n",
    "    t_compress = clock() - ts\n",
    "    t_compresses.append(t_compress)\n",
    "    log.debug(\"Compression using compression_factor = %.3f took %.1f seconds\" % (compression_factor, t_compress))\n",
    "\n",
    "    template_vis.data['vis']*=0.0\n",
    "    ts = clock()\n",
    "    dcvt = dcvt = decompress_visibility(cvt, vt, cindex=cindex, compression='tb')\n",
    "    t_decompress = clock() - ts\n",
    "    t_decompresses.append(t_decompress)\n",
    "    log.debug(\"Decompression took %.1f seconds\" % (t_decompress))\n",
    "    \n",
    "    ts = clock()\n",
    "    dcdirtyimage, dcsumwt=invert_2d(dcvt, model)\n",
    "    dcdirtyimage=normalize_sumwt(dcdirtyimage, dcsumwt)\n",
    "    t_invert.append(clock() - ts)\n",
    "\n",
    "    dcdirtyimage.data -= dirtyimage.data\n",
    "    show_image(dcdirtyimage)\n",
    "    plt.title('Recovery error')\n",
    "    plt.show()\n",
    "    dcqa = qa_image(dcdirtyimage, mask=mask)\n",
    "    \n",
    "    print(\"Decompressed compressed image\", dcqa)\n",
    "    signal.append(qa.data['max'])\n",
    "    error_peak.append(dcqa.data['max'])\n",
    "    error_medianabs.append(dcqa.data['medianabs'])\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(vt.vis.real[:,0,0], vt.vis.imag[:,0,0], '.', color='b', label='Original')\n",
    "    plt.plot(dcvt.vis.real[:,0,0]-vt.vis.real[:,0,0], dcvt.vis.imag[:,0,0]-vt.vis.imag[:,0,0],\n",
    "         '.', color='r', label='error')\n",
    "    plt.xlabel('Real')\n",
    "    plt.ylabel('Imaginary')\n",
    "    plt.legend()\n",
    "    plt.title(\"Compression = %.3f\" %(compression_factor))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.semilogy(compression_factors, signal, color='r', label='Image peak')\n",
    "plt.semilogy(compression_factors, error_peak, color='b', label='Maximum error in image')\n",
    "plt.semilogy(compression_factors, error_medianabs, color='g', label='Median abs error in image')\n",
    "plt.title('Error after compression and decompression')\n",
    "plt.xlabel('Compression factor')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(compression_factors, t_compresses, color='r', label='Compression')\n",
    "plt.plot(compression_factors, t_decompresses, color='b', label='Decompression')\n",
    "plt.plot(compression_factors, t_invert, color='g', label='Invert compressed data')\n",
    "plt.plot(compression_factors, numpy.array(t_invert)+numpy.array(t_compresses), linestyle='dashed',\n",
    "         color='black', label='Compress + Invert')\n",
    "plt.axhline(t_full, color='black', label='Invert full data')\n",
    "plt.legend()\n",
    "plt.title('Time for compress, decompress, and invert')\n",
    "plt.xlabel('Compression factor')\n",
    "plt.ylabel('Time (s)')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
