{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask imaging demonstration\n",
    "\n",
    "This notebook explores the use of dask for parallelisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dask import delayed\n",
    "\n",
    "sys.path.append(os.path.join('..', '..'))\n",
    "\n",
    "results_dir = './results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "from matplotlib import pylab\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (12.0, 12.0)\n",
    "pylab.rcParams['image.cmap'] = 'rainbow'\n",
    "\n",
    "import numpy\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from arl.data.polarisation import PolarisationFrame\n",
    "from arl.data.parameters import get_parameter\n",
    "from arl.visibility.operations import create_visibility, create_visibility_from_rows, copy_visibility\n",
    "from arl.skycomponent.operations import create_skycomponent\n",
    "from arl.image.deconvolution import deconvolve_cube\n",
    "from arl.image.operations import show_image, export_image_to_fits\n",
    "from arl.image.iterators import raster_iter\n",
    "from arl.visibility.iterators import vis_timeslice_iter, vis_wslice_iter\n",
    "from arl.util.testing_support import create_named_configuration\n",
    "from arl.fourier_transforms.ftprocessor import predict_2d, invert_2d, create_image_from_visibility, \\\n",
    "    predict_skycomponent_visibility, residual_image, invert_timeslice_single, invert_wslice_single, \\\n",
    "    predict_timeslice_single, predict_wslice_single,residual_image, advise_wide_field\n",
    "\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.DEBUG)\n",
    "log.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the SKA1-LOW core configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowcore = create_named_configuration('LOWBD2-CORE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the visibility. \n",
    "\n",
    "This just makes the uvw, time, antenna1, antenna2, weight columns in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times = numpy.linspace(-3,+3,13) * (numpy.pi / 12.0)\n",
    "frequency = numpy.array([1e8])\n",
    "channel_bandwidth = numpy.array([1e7])\n",
    "\n",
    "\n",
    "reffrequency = numpy.max(frequency)\n",
    "phasecentre = SkyCoord(ra=+15.0 * u.deg, dec=-45.0 * u.deg, frame='icrs', equinox=2000.0)\n",
    "vt = create_visibility(lowcore, times, frequency, channel_bandwidth=channel_bandwidth,\n",
    "                       weight=1.0, phasecentre=phasecentre, polarisation_frame=PolarisationFrame(\"stokesI\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advise on wide field parameters. This returns a dictionary with all the input and calculated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "advice = advise_wide_field(vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a grid of components and predict each in turn, using the full phase term including w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {'npixel': 512,\n",
    "          'cellsize': 0.001,\n",
    "          'spectral_mode': 'channel',\n",
    "          'channel_bandwidth': 5e7,\n",
    "          'reffrequency': 1e8,\n",
    "          'kernel':'calculated',\n",
    "          'facets':4}\n",
    "\n",
    "npixel = 512\n",
    "cellsize=0.001\n",
    "facets = 4\n",
    "flux = numpy.array([[100.0]])\n",
    "\n",
    "model = create_image_from_visibility(vt, npixel=512, cellsize=0.001, npol=1)\n",
    "spacing_pixels = npixel // facets\n",
    "log.info('Spacing in pixels = %s' % spacing_pixels)\n",
    "spacing = 180.0 * cellsize * spacing_pixels / numpy.pi\n",
    "centers = -1.5, -0.5, +0.5, +1.5\n",
    "for iy in centers:\n",
    "    for ix in centers:\n",
    "        pra =  int(round(npixel // 2 + ix * spacing_pixels - 1))\n",
    "        pdec = int(round(npixel // 2 + iy * spacing_pixels - 1))\n",
    "        sc = pixel_to_skycoord(pra, pdec, model.wcs)\n",
    "        log.info(\"Component at (%f, %f) %s\" % (pra, pdec, str(sc)))\n",
    "        comp = create_skycomponent(flux=flux, frequency=frequency, direction=sc, \n",
    "                                   polarisation_frame=PolarisationFrame(\"stokesI\"))\n",
    "        predict_skycomponent_visibility(vt, comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Dask enabled invert looking like invert_2d but with additional arguments for the invert for a single chunk, and the iterator. The iterator is used to split the visibility up into pieces before calling the\n",
    "single chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def invert_dask(vt, model, dopsf=False, normalize=True, invert_single=invert_2d, iterator=vis_timeslice_iter, \n",
    "                **kwargs):\n",
    "\n",
    "    def accumulate_results(results, normalize=normalize):\n",
    "        acc = []\n",
    "        sumwt = 0.0\n",
    "        nresults = len(results)\n",
    "        for i, result in enumerate(results):\n",
    "            if i>0:\n",
    "                acc.data += result[0].data\n",
    "                sumwt += result[1]\n",
    "            else:\n",
    "                acc = result[0]\n",
    "                sumwt = result[1]\n",
    "        \n",
    "        if normalize:\n",
    "            acc.data /= float(sumwt)\n",
    "            \n",
    "        return acc, sumwt \n",
    "\n",
    "    results = list()\n",
    "\n",
    "    for rows in iterator(vt, **kwargs):\n",
    "        v = copy_visibility(create_visibility_from_rows(vt, rows))\n",
    "        result = delayed(invert_single, pure=True)(v, model, dopsf=dopsf, normalize=False, **kwargs)\n",
    "        results.append(result)\n",
    "\n",
    "    return delayed(accumulate_results, pure=True)(results, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirty_2d_dask = invert_dask(vt, model, False, invert_single=invert_2d, iterator=vis_timeslice_iter, normalize=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can execute the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirty_2d, sumwt_2d = dirty_2d_dask.compute()\n",
    "show_image(dirty_2d)\n",
    "\n",
    "print(\"Max, min in dirty image = %.6f, %.6f, sumwt = %s\" % (dirty_2d.data.max(), dirty_2d.data.min(),\n",
    "     sumwt_2d))\n",
    "\n",
    "export_image_to_fits(dirty_2d, '%s/imaging-dask_2d.fits' % (results_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same thing but with improved invert and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirty_wslice_dask = invert_dask(vt, model, False, invert_single=invert_wslice_single, iterator=vis_wslice_iter,\n",
    "                           normalize=False, wslice=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirty_wslice, sumwt_wslice = dirty_wslice_dask.compute()\n",
    "show_image(dirty_wslice)\n",
    "\n",
    "print(\"Max, min in dirty image = %.6f, %.6f, sumwt = %s\" % (dirty_wslice.data.max(), dirty_wslice.data.min(),\n",
    "     sumwt_wslice))\n",
    "\n",
    "export_image_to_fits(dirty_wslice, '%s/imaging-dask_wslice.fits' % (results_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do timeslicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirty_timeslice_dask = invert_dask(vt, model, False, invert_single=invert_timeslice_single, \n",
    "                                   iterator=vis_timeslice_iter, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirty_timeslice, sumwt_timeslice = dirty_timeslice_dask.compute()\n",
    "show_image(dirty_timeslice)\n",
    "\n",
    "print(\"Max, min in dirty image = %.6f, %.6f, sumwt = %s\" % (dirty_timeslice.data.max(), dirty_timeslice.data.min(),\n",
    "     sumwt_timeslice))\n",
    "\n",
    "export_image_to_fits(dirty_timeslice, '%s/imaging-dask_timeslice.fits' % (results_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_dask(vt, model, predict_single=predict_timeslice_single, iterator=vis_timeslice_iter, **kwargs):\n",
    "\n",
    "    \n",
    "    def accumulate_results(results):\n",
    "        i=0\n",
    "        for rows in iterator(vt, **kwargs):\n",
    "            visslice = create_visibility_from_rows(vt, rows)\n",
    "            vt.data['vis'][rows] += results[i].data['vis']\n",
    "            i+=1\n",
    "            \n",
    "        return vt \n",
    "\n",
    "    results = list()\n",
    "\n",
    "    for rows in iterator(vt, **kwargs):\n",
    "        visslice = copy_visibility(create_visibility_from_rows(vt, rows))\n",
    "        result = delayed(predict_single, pure=True)(visslice, model, **kwargs)\n",
    "        results.append(result)\n",
    "\n",
    "    return delayed(accumulate_results, pure=True)(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vtpred = copy_visibility(vt)\n",
    "predict_timeslice_dask = predict_dask(vtpred, model, predict_single=predict_timeslice_single, \n",
    "                                      iterator=vis_timeslice_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vtpred = predict_timeslice_dask.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will turn to major/minor cycle cleaning. In this case, it turns out that we would benefit from the residual_image function since it does predict/invert on a single chunk rather than doing predict on all chunks and then invert on all chunks.\n",
    "\n",
    "First we need the corresponding dask function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def residual_dask(vis, visres, model, iterator=vis_timeslice_iter, **kwargs):\n",
    "\n",
    "    def accumulate_results(results):\n",
    "        i=0\n",
    "        for rows in iterator(visres, **kwargs):\n",
    "            visslice = create_visibility_from_rows(visres, rows)\n",
    "            visres.data['vis'][rows] = results[i][0].data['vis']\n",
    "            i+=1           \n",
    "\n",
    "        acc = []\n",
    "        sumwt = 0.0\n",
    "        nresults = len(results)\n",
    "        for i, result in enumerate(results):\n",
    "            if i>0:\n",
    "                acc.data += result[1].data\n",
    "                sumwt += result[2]\n",
    "            else:\n",
    "                acc = result[1]\n",
    "                sumwt = result[2]\n",
    "        \n",
    "        acc.data /= float(sumwt)\n",
    "            \n",
    "        return visres, acc, sumwt\n",
    "\n",
    "    results = list()\n",
    "\n",
    "    for rows in iterator(vis, **kwargs):\n",
    "        visslice = copy_visibility(create_visibility_from_rows(vis, rows))\n",
    "        result = delayed(residual_image, pure=True)(visslice, model, normalize=False, **kwargs)\n",
    "        results.append(result)\n",
    "\n",
    "    return delayed(accumulate_results, pure=True)(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the timeslice functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "residual_timeslice_dask = residual_dask(vt, vtpred, model, \n",
    "                                        predict_residual=predict_timeslice_single, \n",
    "                                        invert_residual=invert_timeslice_single,\n",
    "                                        iterator=vis_timeslice_iter)\n",
    "residual_timeslice_dask.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we make a version of solve_image adapted to this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def solve_image_dask(vis, model, components=None, residual=residual_dask, invert=invert_dask, **kwargs):\n",
    "    \"\"\"Solve for image using deconvolve_cube and specified predict, invert\n",
    "\n",
    "    This is the same as a majorcycle/minorcycle algorithm. The components are removed prior to deconvolution.\n",
    "\n",
    "    See also arguments for predict, invert, deconvolve_cube functions.2d\n",
    "\n",
    "    :param vis:\n",
    "    :param model: Model image\n",
    "    :param predict: Predict function e.g. predict_2d, predict_wslice\n",
    "    :param invert: Invert function e.g. invert_2d, invert_wslice\n",
    "    :returns: Visibility, model\n",
    "    \"\"\"\n",
    "    nmajor = get_parameter(kwargs, 'nmajor', 5)\n",
    "    log.info(\"solve_image: Performing %d major cycles\" % nmajor)\n",
    "    \n",
    "    # The model is added to each major cycle and then the visibilities are\n",
    "    # calculated from the full model\n",
    "    visres = copy_visibility(vis)\n",
    "    visres.data['vis'][...] = 0.0\n",
    "\n",
    "    dask_residual=residual(vis, visres, model, **kwargs)\n",
    "    visres, dirty, sumwt = dask_residual.compute()\n",
    "    \n",
    "    if components is not None:\n",
    "        vispred = predict_skycomponent_visibility(vispred, components)\n",
    "    \n",
    "    dask_psf = invert(visres, model, dopsf=True, **kwargs)\n",
    "    psf, sumwt = dask_psf.compute()\n",
    "    \n",
    "    thresh = get_parameter(kwargs, \"threshold\", 0.0)\n",
    "    \n",
    "    for i in range(nmajor):\n",
    "        log.info(\"solve_image: Start of major cycle %d\" % i)\n",
    "        cc, res = deconvolve_cube(dirty, psf, **kwargs)\n",
    "        model.data += cc.data\n",
    "        dask_residual=residual(vis, visres, model, **kwargs)\n",
    "        visres, dirty, sumwt = dask_residual.compute()\n",
    "        if numpy.abs(dirty.data).max() < 1.1 * thresh:\n",
    "            log.info(\"Reached stopping threshold %.6f Jy\" % thresh)\n",
    "            break\n",
    "        log.info(\"solve_image: End of major cycle\")\n",
    "    \n",
    "    log.info(\"solve_image: End of major cycles\")\n",
    "    return visres, model, dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can solve for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.data*=0.0\n",
    "visres, model, residual = solve_image_dask(vt, model=model, invert=invert_dask, \n",
    "                                           invert_residual=invert_timeslice_single, \n",
    "                                           predict_residual=predict_timeslice_single, \n",
    "                                           iterator=vis_timeslice_iter, algorithm='hogbom',\n",
    "                                           niter=1000, fractional_threshold=0.1,\n",
    "                                           threshold=1.0, nmajor=3, gain=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_image(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
