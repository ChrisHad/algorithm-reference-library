{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask imaging demonstration\n",
    "\n",
    "This notebook explores the use of dask for parallelisation. We work through the steps of imaging, ending up with a major/minor cycle algorithm using dask.\n",
    "\n",
    "For each step, we first create a graph and then execute it to demonstrate correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dask import delayed\n",
    "\n",
    "sys.path.append(os.path.join('..', '..'))\n",
    "\n",
    "results_dir = './results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "from matplotlib import pylab\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (12.0, 12.0)\n",
    "pylab.rcParams['image.cmap'] = 'rainbow'\n",
    "\n",
    "import numpy\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from arl.data.polarisation import PolarisationFrame\n",
    "from arl.data.parameters import get_parameter\n",
    "from arl.visibility.operations import create_visibility, create_visibility_from_rows, copy_visibility\n",
    "from arl.skycomponent.operations import create_skycomponent\n",
    "from arl.image.deconvolution import deconvolve_cube, restore_cube\n",
    "from arl.image.operations import show_image, export_image_to_fits\n",
    "from arl.image.iterators import raster_iter\n",
    "from arl.visibility.iterators import vis_timeslice_iter, vis_timeslice_iter\n",
    "from arl.util.testing_support import create_named_configuration\n",
    "from arl.fourier_transforms.ftprocessor import predict_2d, invert_2d, create_image_from_visibility, \\\n",
    "    predict_skycomponent_visibility, residual_image, invert_timeslice_single, invert_timeslice_single, \\\n",
    "    predict_timeslice_single, predict_timeslice_single,advise_wide_field\n",
    "\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)\n",
    "log.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the visibility. \n",
    "\n",
    "This just makes the uvw, time, antenna1, antenna2, weight columns in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowcore = create_named_configuration('LOWBD2-CORE')\n",
    "times = numpy.linspace(-3,+3,13) * (numpy.pi / 12.0)\n",
    "frequency = numpy.array([1e8])\n",
    "channel_bandwidth = numpy.array([1e7])\n",
    "\n",
    "\n",
    "reffrequency = numpy.max(frequency)\n",
    "phasecentre = SkyCoord(ra=+15.0 * u.deg, dec=-45.0 * u.deg, frame='icrs', equinox=2000.0)\n",
    "vt = create_visibility(lowcore, times, frequency, channel_bandwidth=channel_bandwidth,\n",
    "                       weight=1.0, phasecentre=phasecentre, polarisation_frame=PolarisationFrame(\"stokesI\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advise on wide field parameters. This returns a dictionary with all the input and calculated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "advice = advise_wide_field(vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a grid of components and predict each in turn, using the full phase term including w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "npixel = 512\n",
    "cellsize=0.001\n",
    "flux = numpy.array([[100.0]])\n",
    "facets = 4\n",
    "\n",
    "model = create_image_from_visibility(vt, npixel=npixel, cellsize=cellsize, npol=1,\n",
    "                                    polarisation_frame=PolarisationFrame(\"stokesI\"))\n",
    "spacing_pixels = npixel // facets\n",
    "log.info('Spacing in pixels = %s' % spacing_pixels)\n",
    "spacing = 180.0 * cellsize * spacing_pixels / numpy.pi\n",
    "centers = -1.5, -0.5, +0.5, +1.5\n",
    "comps = list()\n",
    "for iy in centers:\n",
    "    for ix in centers:\n",
    "        pra =  int(round(npixel // 2 + ix * spacing_pixels - 1))\n",
    "        pdec = int(round(npixel // 2 + iy * spacing_pixels - 1))\n",
    "        sc = pixel_to_skycoord(pra, pdec, model.wcs)\n",
    "        log.info(\"Component at (%f, %f) %s\" % (pra, pdec, str(sc)))\n",
    "        comps.append(create_skycomponent(flux=flux, frequency=frequency, direction=sc, \n",
    "                                         polarisation_frame=PolarisationFrame(\"stokesI\")))\n",
    "vt = predict_skycomponent_visibility(vt, comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Dask enabled invert looking like invert_2d but with additional arguments for the invert for a single chunk, and the iterator. The iterator is used to split the visibility up into pieces before calling the\n",
    "single chunk invert.\n",
    "\n",
    "The function invert_graph is not a graph but it takes graphs as input and emits a graph to do the calculation. The dask.delayed method compute() must be called to actually execute the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_graph = delayed(create_image_from_visibility)(vt, npixel=512, cellsize=0.001, npol=1)\n",
    "\n",
    "def create_invert_graph(vt, model_graph, dopsf=False, normalize=True, invert_single=invert_2d, \n",
    "                        iterator=vis_timeslice_iter, **kwargs):\n",
    "\n",
    "    def accumulate_results(results, normalize=normalize, dopsf=False):\n",
    "        if dopsf:\n",
    "            log.info('invert_graph: summing PSFs')\n",
    "        else:\n",
    "            log.info('invert_graph: summing dirty images')\n",
    "\n",
    "\n",
    "        acc = []\n",
    "        sumwt = 0.0\n",
    "        nresults = len(results)\n",
    "        for i, result in enumerate(results):\n",
    "            if i>0:\n",
    "                acc.data += result[0].data\n",
    "                sumwt += result[1]\n",
    "            else:\n",
    "                acc = result[0]\n",
    "                sumwt = result[1]\n",
    "        \n",
    "        if normalize:\n",
    "            acc.data /= float(sumwt)\n",
    "            \n",
    "        return acc, sumwt \n",
    "\n",
    "    results = list()\n",
    "\n",
    "    for rows in iterator(vt, **kwargs):\n",
    "        v = copy_visibility(create_visibility_from_rows(vt, rows))\n",
    "        result = delayed(invert_single, pure=True)(v, model_graph, dopsf=dopsf, normalize=False, **kwargs)\n",
    "        results.append(result)\n",
    "\n",
    "    return delayed(accumulate_results, pure=True)(results, normalize, dopsf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the model graph is just a delayed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can make a graph for a particular context and then visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirty_timeslice_graph = create_invert_graph(vt, model, False, invert_single=invert_timeslice_single, \n",
    "                                     iterator=vis_timeslice_iter, normalize=False, timeslice=10.0, context='')\n",
    "dirty_timeslice_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a deconvolve graph. This will need graphs to calculate the dirty (or residual) image and the psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_deconvolve_graph(dirty_graph, psf_graph, model_graph, **kwargs):\n",
    "    def deconvolve_model_only(dirty, psf, model, **kwargs):\n",
    "        log.info('deconvolve_graph: Starting deconvolution')\n",
    "        result = deconvolve_cube(dirty, psf, **kwargs)[0]\n",
    "        log.info('deconvolve_graph: Finished deconvolution')\n",
    "        result.data += model.data\n",
    "        return result\n",
    "    return delayed(deconvolve_model_only, pure=True)(dirty_graph[0], psf_graph[0], model_graph, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "psf_graph = create_invert_graph(vt, model_graph, dopsf=True, invert_single=invert_timeslice_single, \n",
    "                                iterator=vis_timeslice_iter, normalize=False, timeslice=10.0)\n",
    "dirty_graph = create_invert_graph(vt, model_graph, False, invert_single=invert_timeslice_single, \n",
    "                                  iterator=vis_timeslice_iter, normalize=False, timeslice=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualize a graph to perform a deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_model_graph = create_deconvolve_graph(dirty_graph, psf_graph, model_graph, niter=1000, algorithm='hogbom',\n",
    "                                    gain=0.1)\n",
    "clean_model_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need a graph to calculate residuals. For this we have added a new function in ftprocessor that \n",
    "calculates residuals per visibility chunk. This works for timeslicing and wslicing but not for faceting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_residual_graph(vis, model_graph, iterator=vis_timeslice_iter, **kwargs):\n",
    "\n",
    "    def accumulate_residuals(results, rowses):\n",
    "        log.info('residual_graph: summing residual images')\n",
    "        acc = []\n",
    "        sumwt = 0.0\n",
    "\n",
    "        for i, result in enumerate(results):\n",
    "            if i>0:\n",
    "                acc.data += result[1].data\n",
    "                sumwt += result[2]\n",
    "            else:\n",
    "                acc = result[1]\n",
    "                sumwt = result[2]\n",
    "        \n",
    "        acc.data /= float(sumwt)\n",
    "        f=show_image(acc, title=\"Residual image\")\n",
    "        return acc, sumwt\n",
    "\n",
    "    results = list()\n",
    "    rowses = list()\n",
    "\n",
    "    for rows in iterator(vis, **kwargs):\n",
    "        rowses.append(rows)\n",
    "        visslice = copy_visibility(create_visibility_from_rows(vis, rows))\n",
    "        # Each result is tuple: resid vis, resid image, sumwt\n",
    "        result = delayed(residual_image, pure=True)(visslice, model_graph, normalize=False, **kwargs)\n",
    "        results.append(result)\n",
    "\n",
    "    # We return a tuple: resid vis, residual image, sumwt\n",
    "    return delayed(accumulate_residuals, pure=True)(results, rowses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the arguments predict_residual and invert_residual are passed to the ftprocessor.residual function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "residual_timeslice_graph = create_residual_graph(vt, model_graph, \n",
    "                                                 predict_residual=predict_timeslice_single, \n",
    "                                                 invert_residual=invert_timeslice_single, \n",
    "                                                 iterator=vis_timeslice_iter)\n",
    "residual_timeslice_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we create a function that can make graphs for solve_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_solve_image_graph(vis, model_graph, \n",
    "                             create_residual_graph=create_residual_graph, \n",
    "                             create_invert_graph=create_invert_graph,\n",
    "                             create_deconvolve_graph=create_deconvolve_graph, **kwargs):\n",
    "\n",
    "    psf_graph = create_invert_graph(vis, model_graph, dopsf=True, **kwargs)\n",
    "\n",
    "    res_graph_list = list()\n",
    "    model_graph_list = list()\n",
    "    \n",
    "    nmajor = get_parameter(kwargs, \"nmajor\", 5)\n",
    "    \n",
    "    res_graph_list.append(create_residual_graph(vis, model_graph, **kwargs))    \n",
    "    model_graph_list.append(create_deconvolve_graph(res_graph_list[-1], psf_graph, model_graph, **kwargs))\n",
    "    \n",
    "    for cycle in range(1, nmajor):\n",
    "        res_graph_list.append(create_residual_graph(vis, model_graph_list[-1], **kwargs))    \n",
    "        model_graph_list.append(create_deconvolve_graph(res_graph_list[-1], psf_graph, \n",
    "                                                 model_graph_list[cycle-1], **kwargs))\n",
    "    \n",
    "    return model_graph_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the graph that will do the deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_graph = delayed(create_image_from_visibility)(vt, npixel=512, cellsize=0.001, npol=1)\n",
    "\n",
    "solution_graph = create_solve_image_graph(vt, model_graph=model_graph, \n",
    "                                          invert=create_invert_graph, \n",
    "                                          invert_residual=invert_timeslice_single, \n",
    "                                          predict_residual=predict_timeslice_single, \n",
    "                                          iterator=vis_timeslice_iter, algorithm='hogbom',\n",
    "                                          niter=1000, fractional_threshold=0.1,\n",
    "                                          threshold=1.0, nmajor=5, gain=0.1)\n",
    "solution_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to restore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_restore_graph(model_graph, psf_graph, residual_graph, **kwargs):\n",
    "    return delayed(restore_cube, pure=True)(model_graph, psf_graph[0], residual_graph[0], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the residual graph and create the restore graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "residual_timeslice_graph = create_residual_graph(vt, solution_graph,\n",
    "                                                 predict_residual=predict_timeslice_single, \n",
    "                                                 invert_residual=invert_timeslice_single, \n",
    "                                                 iterator=vis_timeslice_iter)\n",
    "restore = create_restore_graph(solution_graph, psf_graph, residual_timeslice_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restore.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = restore.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=show_image(result, title='Restored clean image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
